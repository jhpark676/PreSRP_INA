{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1oR4e4dewrPYjmV0WnueIAkpo4GEP6Dpo","authorship_tag":"ABX9TyPV2hsWaJTrNpQcZyjC85h8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Step 0. 데이터셋 준비하기**   \n","인공지능 모델 학습에 필요한 라이브러리, 유틸리티 함수, 데이터셋을 준비한다."],"metadata":{"id":"QyMh5MCpw36L"}},{"cell_type":"markdown","source":["**Step 0-1. 기본 라이브러리 함수 준비**"],"metadata":{"id":"yvfMdvuDzwnI"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy, math, pdb, sys, time, importlib, datetime\n","import torchvision.transforms as transforms\n","import random\n","import glob\n","import os\n","import torchvision\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda.amp import autocast, GradScaler\n","from tqdm import tqdm\n","from PIL import Image\n","from sklearn import metrics\n","from operator import itemgetter\n","\n","def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n","        res.append(correct_k.mul_(100.0 / batch_size))\n","    return res\n","\n","def tuneThresholdfromScore(scores, labels, target_fa, target_fr = None):\n","    \"\"\"Get error rate from score-label pairs. Tune threshold for similarity score.\"\"\"\n","    fpr, tpr, thresholds = metrics.roc_curve(labels, scores, pos_label=1)\n","    fnr = 1 - tpr\n","\n","    tunedThreshold = [];\n","    if target_fr:\n","        for tfr in target_fr:\n","            idx = numpy.nanargmin(numpy.absolute((tfr - fnr)))\n","            tunedThreshold.append([thresholds[idx], fpr[idx], fnr[idx]]);\n","\n","    for tfa in target_fa:\n","        idx = numpy.nanargmin(numpy.absolute((tfa - fpr))) # numpy.where(fpr<=tfa)[0][-1]\n","        tunedThreshold.append([thresholds[idx], fpr[idx], fnr[idx]]);\n","\n","    idxE = numpy.nanargmin(numpy.absolute((fnr - fpr)))\n","    eer  = max(fpr[idxE],fnr[idxE])*100\n","\n","    return (tunedThreshold, eer, fpr, fnr);\n","\n","def round_down(num, divisor):\n","    return num - (num%divisor)\n","\n","def worker_init_fn(worker_id):\n","    numpy.random.seed(numpy.random.get_state()[1][0] + worker_id)"],"metadata":{"id":"JUkKSgqfuYqH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 0-2. Google Drive 에서 인물 사진 데이터를 가져오기**"],"metadata":{"id":"Lr_DMn3vz16_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KN9hEdMplq3Y"},"outputs":[],"source":["from google.colab import drive\n","import zipfile\n","\n","drive.mount('/content/drive')\n","############################################# TODO #############################################\n","\n","zip_path =       # 이미지 압축 파일 위치 지정\n","output_path =    # 압축 해제 위치 지정\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(output_path)\n","\n","val_path =      # val_pairs.csv 파일 위치 지정\n","!cp \"$val_path\" \"$output_path\"\n","\n","################################################################################################"]},{"cell_type":"markdown","source":["**Step 0-3. 학습 데이터셋 준비**"],"metadata":{"id":"SRZjYmrJ0CCC"}},{"cell_type":"code","source":["class meta_loader(Dataset):\n","    def __init__(self, train_path, train_ext, transform):\n","\n","        ## Read Training Files\n","        files = glob.glob('%s/*/*.%s'%(train_path,train_ext))\n","\n","        ## Make a mapping from Class Name to Class Number\n","        dictkeys = list(set([x.split('/')[-2] for x in files]))\n","        dictkeys.sort()\n","        dictkeys = { key : ii for ii, key in enumerate(dictkeys) }\n","\n","        self.transform  = transform\n","\n","        self.label_dict = {}\n","        self.data_list  = []\n","        self.data_label = []\n","\n","        for lidx, file in enumerate(files):\n","            speaker_name = file.split('/')[-2]\n","            speaker_label = dictkeys[speaker_name];\n","\n","            if not (speaker_label in self.label_dict):\n","                self.label_dict[speaker_label] = [];\n","\n","            self.label_dict[speaker_label].append(lidx);\n","\n","            self.data_label.append(speaker_label)\n","            self.data_list.append(file)\n","\n","        print('{:d} files from {:d} classes found.'.format(len(self.data_list),len(self.label_dict)))\n","\n","    def __getitem__(self, indices):\n","\n","        feat = []\n","        for index in indices:\n","            feat.append(self.transform(Image.open(self.data_list[index])));\n","        feat = numpy.stack(feat, axis=0)\n","\n","        return torch.FloatTensor(feat), self.data_label[index]\n","\n","    def __len__(self):\n","\n","        return len(self.data_list)\n","\n","class meta_sampler(torch.utils.data.Sampler):\n","    def __init__(self, data_source, nPerClass, max_img_per_cls, batch_size):\n","\n","        self.label_dict         = data_source.label_dict\n","        self.nPerClass          = nPerClass\n","        self.max_img_per_cls    = max_img_per_cls;\n","        self.batch_size         = batch_size;\n","\n","        self.num_iters          = 0\n","\n","    def __iter__(self):\n","\n","        ## Get a list of identities\n","        dictkeys = list(self.label_dict.keys());\n","        dictkeys.sort()\n","\n","        lol = lambda lst, sz: [lst[i:i+sz] for i in range(0, len(lst), sz)]\n","\n","        flattened_list = []\n","        flattened_label = []\n","\n","        ## Data for each class\n","        for findex, key in enumerate(dictkeys):\n","            data    = self.label_dict[key]\n","            numSeg  = round_down(min(len(data),self.max_img_per_cls),self.nPerClass)\n","\n","            rp      = lol(numpy.random.permutation(len(data))[:numSeg],self.nPerClass)\n","            flattened_label.extend([findex] * (len(rp)))\n","            for indices in rp:\n","                flattened_list.append([data[i] for i in indices])\n","\n","        ## Data in random order\n","        mixid           = numpy.random.permutation(len(flattened_label))\n","        mixlabel        = []\n","        mixmap          = []\n","\n","        ## Prevent two pairs of the same speaker in the same batch\n","        for ii in mixid:\n","            startbatch = len(mixlabel) - len(mixlabel) % self.batch_size\n","            if flattened_label[ii] not in mixlabel[startbatch:]:\n","                mixlabel.append(flattened_label[ii])\n","                mixmap.append(ii)\n","\n","        batch_indices = [flattened_list[i] for i in mixmap]\n","\n","        self.num_iters = len(batch_indices)\n","\n","        return iter(batch_indices)\n","\n","    def __len__(self):\n","        return self.num_iters\n","\n","def get_data_loader(batch_size, max_img_per_cls, nDataLoaderThread, nPerClass, train_path, train_ext, transform):\n","\n","    train_dataset = meta_loader(train_path, train_ext, transform)\n","\n","    train_sampler = meta_sampler(train_dataset, nPerClass, max_img_per_cls, batch_size)\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset,\n","        batch_size=batch_size,\n","        num_workers=nDataLoaderThread,\n","        sampler=train_sampler,\n","        pin_memory=False,\n","        worker_init_fn=worker_init_fn,\n","        drop_last=True,\n","    )\n","\n","    return train_loader"],"metadata":{"id":"B_-Hc3oYuydP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 0-4. 테스트 데이터셋 준비**"],"metadata":{"id":"EONmFI0j0dys"}},{"cell_type":"code","source":["class test_dataset_loader(Dataset):\n","    def __init__(self, test_list, test_path, transform):\n","        self.test_path  = test_path\n","        self.data_list  = test_list\n","        self.transform  = transform\n","\n","    def __getitem__(self, index):\n","        img = Image.open(os.path.join(self.test_path, self.data_list[index]))\n","        return self.transform(img), self.data_list[index]\n","\n","    def __len__(self):\n","        return len(self.data_list)\n"],"metadata":{"id":"eWX-L5UIu-fX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Step 1. 인공지능 모델 구성하기**   \n","얼굴 인식을 위한 인공지능 모델을 만든다."],"metadata":{"id":"1YUbbfVOwMFV"}},{"cell_type":"markdown","source":["**Step 1-1. Backbone network 선택**   \n","이미지를 임베딩 할 수 있는 Backbone network을 만든다."],"metadata":{"id":"ZstmUWPR2hD8"}},{"cell_type":"code","source":["def MainModel(nOut=1024):\n","    ## Define your own backbone network\n","    ############################################# TODO #############################################\n","\n","    ################################################################################################\n","    return torchvision.models.resnet18(num_classes=nOut) ## Example: Resnet\n",""],"metadata":{"id":"NR3U5bFu6IHZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 1-2. Loss Function 선택**   \n","임베딩한 벡터와 원본 Label과의 차이를 비교할 수 있는 Loss Function을 만든다."],"metadata":{"id":"V93az3Wg2_0D"}},{"cell_type":"code","source":["\n","class LossFunction(nn.Module):\n","    ## Define your own loss function\n","    ############################################# TODO #############################################\n","\n","    ################################################################################################\n","\n","    # Example: Triplet Loss\n","    def __init__(self, hard_rank=0, hard_prob=0, margin=0, **kwargs):\n","        super(LossFunction, self).__init__()\n","\n","        self.test_normalize = True\n","        self.hard_rank  = hard_rank\n","        self.hard_prob  = hard_prob\n","        self.margin     = margin\n","\n","        print('Initialised Triplet Loss')\n","\n","    def forward(self, x, label=None):\n","        assert x.size()[1] == 2\n","\n","        # Normalize anchor and positive\n","        out_anchor      = F.normalize(x[:,0,:], p=2, dim=1)\n","        out_positive    = F.normalize(x[:,1,:], p=2, dim=1)\n","\n","        # Choose appropriate negative indices\n","        negidx      = self.choose_negative(out_anchor.detach(),out_positive.detach(),type='any')\n","\n","        # Get negative pairs\n","        out_negative = out_positive[negidx,:]\n","\n","        ## Calculate positive and negative pair distances\n","        pos_dist    = F.pairwise_distance(out_anchor,out_positive)\n","        neg_dist    = F.pairwise_distance(out_anchor,out_negative)\n","\n","        ## Triplet loss function\n","        nloss   = torch.mean(F.relu(torch.pow(pos_dist, 2) - torch.pow(neg_dist, 2) + self.margin))\n","\n","        return nloss\n","    ## ===== ===== ===== ===== ===== ===== ===== =====\n","    ## Negative mining\n","    ## ===== ===== ===== ===== ===== ===== ===== =====\n","    def choose_negative(self, embed_a, embed_p, type=None):\n","        # Get batch size\n","        batch_size = embed_a.size(0)\n","\n","        # Positive and negative indices\n","        negidx = [] # empty list to fill\n","        allidx = range(0,batch_size)\n","\n","        for idx in allidx:\n","            excidx = list(allidx)\n","            excidx.pop(idx)\n","            if type == 'any':\n","                # Random negative mining\n","                negidx.append(random.choice(excidx))\n","            else:\n","                ValueError('Undefined type of mining.')\n","\n","        return negidx"],"metadata":{"id":"x-vZ5Uvu7FCz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 1-3. Optimizer 선택**   \n","인공지능 모델의 파라미터들을 업데이트 할 optimizer를 만든다."],"metadata":{"id":"vJR7IQAX3ZCM"}},{"cell_type":"code","source":["def Optimizer(parameters, lr, weight_decay):\n","\t## Define your own optimizer\n","\t############################################# TODO #############################################\n","\n","\t################################################################################################\n","\treturn torch.optim.Adam(parameters, lr = lr, weight_decay = weight_decay); ## Example: Adam optimizer"],"metadata":{"id":"FJwEEzA-8kws"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 1-4. Learning Rate Scheduler 선택**   \n","Learning Rate을 조절할 scheduler를 만든다."],"metadata":{"id":"wdm2LaUE3jUh"}},{"cell_type":"code","source":["def Scheduler(optimizer, test_interval, max_epoch, lr_decay):\n","\t## Define your own learning rate scheduler\n","\t############################################# TODO #############################################\n","\n","\t################################################################################################\n","\n","\t## Example: stepLR scheduler\n","\tsche_fn = torch.optim.lr_scheduler.StepLR(optimizer, step_size=test_interval, gamma=lr_decay)\n","\tlr_step = 'epoch'\n","\treturn sche_fn, lr_step"],"metadata":{"id":"J3pbES2X8uWv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 1-5. 임베딩 네트워크 구성**   \n","위의 요소들을 사용하여 임베딩 네트워크를 구성한다."],"metadata":{"id":"J2QQ3I4e4Rz-"}},{"cell_type":"code","source":["class EmbedNet(nn.Module):\n","\n","    def __init__(self, nPerClass, nOut):\n","        super(EmbedNet, self).__init__();\n","\n","        ## Define an embedding model(Backbone network)\n","        ############################################# TODO #############################################\n","\n","        ################################################################################################\n","\n","        ## Define a loss function\n","        ############################################# TODO #############################################\n","\n","        ################################################################################################\n","\n","        ## Number of examples per identity per batch\n","        self.nPerClass = nPerClass\n","\n","    def forward(self, data, label=None):\n","        data    = data.reshape(-1,data.size()[-3],data.size()[-2],data.size()[-1])\n","        ## Extract embedding vector from data\n","        ############################################# TODO #############################################\n","        outp =\n","        ################################################################################################\n","\n","        if label == None:\n","            ## Eval-only. Just return the embedding vector\n","            ############################################# TODO #############################################\n","\n","            ################################################################################################\n","        else:\n","            outp    = outp.reshape(self.nPerClass,-1,outp.size()[-1]).transpose(1,0).squeeze(1)\n","            ## Calculate loss\n","            ############################################# TODO #############################################\n","            nloss =\n","            ################################################################################################\n","            return nloss"],"metadata":{"id":"hLPYqc1rwYHe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 1-6. 모델 학습 오브젝트 생성**   \n","임베딩 네트워크를 학습하기 위한 학습 오브젝트를 생성한다."],"metadata":{"id":"3PMWLqV_gLN6"}},{"cell_type":"code","source":["class ModelTrainer(object):\n","\n","    def __init__(self, embed_model, mixedprec, lr, weight_decay, test_interval, max_epoch, lr_decay):\n","\n","        self.__model__  = embed_model\n","\n","        ## Define optimizer\n","        ############################################# TODO #############################################\n","        self.__optimizer__ =\n","        ################################################################################################\n","\n","        ## Define learning rate scheduler\n","        ############################################# TODO #############################################\n","        self.__scheduler__, self.lr_step =\n","        ################################################################################################\n","\n","        ## For mixed precision training\n","        self.scaler = GradScaler()\n","        self.mixedprec = mixedprec\n","\n","        assert self.lr_step in ['epoch', 'iteration']\n"],"metadata":{"id":"ULOfemiixqU0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 1-6. 인공지능 학습**   \n","해당 인공지능 모델을 학습시키는 함수를 작성한다."],"metadata":{"id":"SRUywqTB4uoo"}},{"cell_type":"code","source":["def train_network(trainer, loader):\n","    trainer.__model__.train();\n","    stepsize = loader.batch_size;\n","    counter = 0;\n","    index   = 0;\n","    loss    = 0;\n","\n","    with tqdm(loader, unit=\"batch\") as tepoch:\n","        for data, label in tepoch:\n","            tepoch.total = tepoch.__len__()\n","            data    = data.transpose(1,0)\n","\n","            ## Reset gradients\n","            ############################################# TODO #############################################\n","\n","            ################################################################################################\n","\n","            ## Forward and backward passes\n","            ############################################# TODO #############################################\n","\n","            ################################################################################################\n","\n","            ## Update status\n","            ############################################# TODO #############################################\n","            loss +=\n","            counter +=\n","            index +=\n","            ################################################################################################\n","\n","            # Print statistics to progress bar\n","            tepoch.set_postfix(loss=loss/counter)\n","\n","            if trainer.lr_step == 'iteration': trainer.__scheduler__.step()\n","        if trainer.lr_step == 'epoch': trainer.__scheduler__.step()\n","\n","    return (loss/counter);"],"metadata":{"id":"zxY_hjGGx2iF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 1-6. 인공지능 평가**   \n","해당 인공지능 모델을 테스트하는 함수를 작성한다."],"metadata":{"id":"JonUvNCK46QY"}},{"cell_type":"code","source":["def evaluateFromList(trainer, test_list, test_path, nDataLoaderThread, transform, print_interval=100):\n","\n","    trainer.__model__.eval();\n","    feats       = {}\n","\n","    ## Read all lines\n","    with open(test_list) as f:\n","        lines = f.readlines()\n","\n","    ## Get a list of unique file names\n","    files = sum([x.strip().split(',')[-2:] for x in lines],[])\n","    setfiles = list(set(files))\n","    setfiles.sort()\n","\n","    ## Define test data loader\n","    test_dataset = test_dataset_loader(setfiles, test_path, transform=transform)\n","    test_loader = torch.utils.data.DataLoader(\n","        test_dataset,\n","        batch_size=1,\n","        shuffle=False,\n","        num_workers=nDataLoaderThread,\n","        drop_last=False,\n","    )\n","\n","    print('Generating embeddings')\n","\n","    ## Extract features for every image\n","    for data in tqdm(test_loader):\n","        inp1                = data[0][0].cuda()\n","        ############################################# TODO #############################################\n","        ref_feat            =\n","        ################################################################################################\n","        feats[data[1][0]]   = ref_feat\n","\n","    all_scores = [];\n","    all_labels = [];\n","    all_trials = []\n","\n","    print('Computing similarities')\n","\n","    ## Read files and compute all scores\n","    for line in tqdm(lines):\n","\n","        data = line.strip().split(',');\n","\n","        ref_feat = feats[data[1]]\n","        com_feat = feats[data[2]]\n","\n","        ## Get cosine similarity between the two features\n","        ############################################# TODO #############################################\n","        score =\n","        ################################################################################################\n","\n","        all_scores.append(score.item());\n","        all_labels.append(int(data[0]));\n","        all_trials.append(data[1] + \",\" + data[2])\n","\n","    return (all_scores, all_labels, all_trials)"],"metadata":{"id":"WTde4Oo8yN13"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 1-6. 파라미터 저장/불러오기**   \n","학습한 파라미터들을 저장하거나 가져오는 함수를 작성한다."],"metadata":{"id":"xlm8SSaD5CCW"}},{"cell_type":"code","source":["def saveParameters(model, path):\n","    torch.save(model.__model__.state_dict(), path);"],"metadata":{"id":"LasRYHiPyl3b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def loadParameters(model, path):\n","    self_state = model.__model__.state_dict();\n","    loaded_state = torch.load(path);\n","    for name, param in loaded_state.items():\n","        origname = name;\n","        if name not in self_state:\n","            if name not in self_state:\n","                print(\"{} is not in the model.\".format(origname));\n","                continue;\n","\n","        if self_state[name].size() != loaded_state[origname].size():\n","            print(\"Wrong parameter length: {}, model: {}, loaded: {}\".format(origname, self_state[name].size(), loaded_state[origname].size()));\n","            continue;\n","\n","        self_state[name].copy_(param);"],"metadata":{"id":"AzmMtmMuytrA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Step 2. 인공지능 모델 학습**   \n","얼굴 인식을 위한 인공지능 모델을 학습한다."],"metadata":{"id":"DdZTVhId-L1J"}},{"cell_type":"markdown","source":["**Step 2-1. 하이퍼 파라미터 설정**   \n","학습에 필요한 하이퍼 파라미터를 설정한다."],"metadata":{"id":"_93TQrg35fnY"}},{"cell_type":"code","source":["# Dataloader\n","batch_size = 64                                       # Batch size\n","max_img_per_cls = 500                                 # Maximum number of images per class per epoch\n","nDataLoaderThread = 5                                 # Number of loader threads\n","\n","# Training\n","test_interval = 5                                     # Test and save the model every this epochs\n","max_epoch = 100                                       # Maximum number of epochs\n","\n","# Optimizer\n","lr = 0.001                                            # Learning rate\n","lr_decay = 0.90                                       # Learning rate decay for steplr scheduler\n","weight_decay = 0                                      # Weight decay in the optimizer\n","\n","# Loss\n","margin = 0.1                                          # Loss margin for some loss functions\n","scale = 30                                            # Loss scale for some loss functions\n","nPerClass = 2                                         # Number of images per class per batch, only for metric learning based losses\n","nClasses = 2000                                       # Number of classes in the softmax layer, only for softmax-based losses\n","\n","# Load/Save\n","initial_model = \"\"                                    # Path of initial model's parameters\n","save_path = \"\"                                        # Output path for logs and parameters\n","\n","# Data\n","train_path = \"\"                                       # Path of train dataset\n","test_path = \"\"                                        # Path of validation dataset\n","test_list = \"\"                                        # Path of list for validation (val_pairs.csv)\n","train_ext = \"jpg\"\n","\n","# Model\n","nOut = 1024                                           # Size of embedding feature vectors\n","\n","# Test only\n","eval = False                                          # Evalation-only knob\n","output = \"\"\n","\n","# Other\n","mixedprec = False\n","gpu = 0"],"metadata":{"id":"E7pD6n9e-OFV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 2-2. 인공지능 모델 학습**   \n","인공지능 모델을 학습하는 코드를 작성한다."],"metadata":{"id":"i1CWBHeS5lsM"}},{"cell_type":"code","source":["os.environ[\"CUDA_VISIBLE_DEVICES\"]='{}'.format(gpu)\n","\n","if not (os.path.exists(save_path)):\n","  os.makedirs(save_path)\n","\n","## Define network\n","############################################# TODO #############################################\n","s =\n","################################################################################################\n","it = 1\n","\n","## Input transformations for training\n","train_transform = transforms.Compose(\n","  [transforms.ToTensor(),\n","    transforms.Resize(256),\n","    transforms.RandomCrop([224,224]),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","\n","## Input transformations for evaluation\n","test_transform = transforms.Compose(\n","  [transforms.ToTensor(),\n","    transforms.Resize(256),\n","    transforms.CenterCrop([224,224]),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","\n","# Initialise trainer and data loader\n","############################################# TODO #############################################\n","trainLoader =\n","trainer =\n","################################################################################################\n","\n","## Load model weights\n","modelfiles = glob.glob('{}/model0*.model'.format(save_path))\n","modelfiles.sort()\n","\n","## If the target directory already exists, start from the existing file\n","if len(modelfiles) >= 1:\n","  loadParameters(trainer, modelfiles[-1]);\n","  print(\"Model {} loaded from previous state!\".format(modelfiles[-1]));\n","  it = int(os.path.splitext(os.path.basename(modelfiles[-1]))[0][5:]) + 1\n","elif(initial_model != \"\"):\n","  loadParameters(trainer, initial_model);\n","  print(\"Model {} loaded!\".format(initial_model));\n","\n","## If the current iteration is not 1, update the scheduler\n","for ii in range(1,it):\n","  trainer.__scheduler__.step()\n","\n","## Print total number of model parameters\n","pytorch_total_params = sum(p.numel() for p in s.__S__.parameters())\n","print('Total model parameters: {:,}'.format(pytorch_total_params))\n","\n","## Evaluation-only code\n","if eval == True:\n","  ## Evaluate network\n","  ############################################# TODO #############################################\n","  sc, lab, trials =\n","  ################################################################################################\n","  result = tuneThresholdfromScore(sc, lab, [1, 0.1]);\n","  print('EER {:.4f}'.format(result[1]))\n","  if output != '':\n","    with open(output,'w') as f:\n","      for ii in range(len(sc)):\n","        f.write('{:4f},{:d},{}\\n'.format(sc[ii],lab[ii],trials[ii]))\n","  quit();\n","\n","## Write args to scorefile for training\n","scorefile = open(save_path+\"/scores.txt\", \"a+\");\n","strtime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","scorefile.flush()\n","\n","## Core training script\n","for it in range(it,max_epoch+1):\n","    clr = [x['lr'] for x in trainer.__optimizer__.param_groups]\n","    print(time.strftime(\"%Y-%m-%d %H:%M:%S\"), it, \"Training epoch {:d} with LR {:.5f} \".format(it,max(clr)));\n","    ############################################# TODO #############################################\n","    loss =\n","    ################################################################################################\n","    if it % test_interval == 0:\n","        ## Evaluate network\n","        ############################################# TODO #############################################\n","        sc, lab, trials =\n","        ################################################################################################\n","        result = tuneThresholdfromScore(sc, lab, [1, 0.1]);\n","\n","        print(\"IT {:d}, Val EER {:.5f}\".format(it, result[1]));\n","        scorefile.write(\"IT {:d}, Val EER {:.5f}\\n\".format(it, result[1]));\n","        saveParameters(trainer, save_path+\"/model{:09d}.model\".format(it));\n","\n","    print(time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"TLOSS {:.5f}\".format(loss));\n","    scorefile.write(\"IT {:d}, TLOSS {:.5f}\\n\".format(it, loss));\n","\n","    scorefile.flush()\n","\n","scorefile.close();"],"metadata":{"id":"Cs-KoabAnflS"},"execution_count":null,"outputs":[]}]}